---
title: "适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现"
author: 尹彬
date: 2020-6-7
output:
  word_document:
    highlight: "tango"
  # pdf_document:
  #   toc: true
  #   toc_depth: 3
  #   number_sections: true
# pandoc_args: ["--toc", "--toc-depth=3"]
presentation:
  # presentation 主题
  # === 可选的主题 ===
  # "beige.css"
  # "black.css"
  # "blood.css"
  # "league.css"
  # "moon.css"
  # "night.css"
  # "serif.css"
  # "simple.css"
  # "sky.css"
  # "solarized.css"
  # "white.css"
  # "none.css"
  theme: sky.css

  # The "normal" size of the presentation, aspect ratio will be preserved
  # when the presentation is scaled to fit different resolutions. Can be
  # specified using percentage units.
  width: 960
  height: 700

  # Factor of the display size that should remain empty around the content
  margin: 0.1

  # Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2
  maxScale: 1.5

  # Display controls in the bottom right corner
  controls: true

  # Display a presentation progress bar
  progress: true

  # Display the page number of the current slide
  slideNumber: true

  # Push each slide change to the browser history
  history: false

  # Enable keyboard shortcuts for navigation
  keyboard: true

  # Enable the slide overview mode
  overview: true

  # Vertical centering of slides
  center: true

  # Enables touch navigation on devices with touch input
  touch: true

  # Loop the presentation
  loop: false

  # Change the presentation direction to be RTL
  rtl: false

  # Randomizes the order of slides each time the presentation loads
  shuffle: false

  # Turns fragments on and off globally
  fragments: true

  # Flags if the presentation is running in an embedded mode,
  # i.e. contained within a limited portion of the screen
  embedded: false

  # Flags if we should show a help overlay when the questionmark
  # key is pressed
  help: true

  # Flags if speaker notes should be visible to all viewers
  showNotes: false

  # Number of milliseconds between automatically proceeding to the
  # next slide, disabled when set to 0, this value can be overwritten
  # by using a data-autoslide attribute on your slides
  autoSlide: 0

  # Stop auto-sliding after user input
  autoSlideStoppable: true

  # Enable slide navigation via mouse wheel
  mouseWheel: true

  # Hides the address bar on mobile devices
  hideAddressBar: true

  # Opens links in an iframe preview overlay
  previewLinks: false

  # Transition style
  transition: "convex" # none/fade/slide/convex/concave/zoom

  # Transition speed
  transitionSpeed: "default" # default/fast/slow

  # Transition style for full page slide backgrounds
  backgroundTransition: "default" # none/fade/slide/convex/concave/zoom

  # Number of slides away from the current that are visible
  viewDistance: 3

  # Parallax background image
  parallaxBackgroundImage: "/assets/bg.jpeg" # e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

  # Parallax background size
  parallaxBackgroundSize: "" # CSS syntax, e.g. "2100px 900px"

  # Number of pixels to move the parallax background per slide
  # - Calculated automatically unless specified
  # - Set to 0 to disable movement along an axis
  parallaxBackgroundHorizontal: null
  parallaxBackgroundVertical: null

  # Enable Speake Notes
  enableSpeakerNotes: false
---

<!-- slide -->

## 适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现

<br/>

### 命题类型：新工科

<!-- slide -->

- **背景介绍**
- 算法价值
- 项目说明
  - 为什么需要融合
  - 硬件准备
  - 参考标准
  - 目标期望
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求

<!-- slide -->

![车路协同介绍](/assets/01jiagou_kmvj7zvwv.png)

<!-- slide -->

1. 车路协同有个应用方向是全息路口应用
2. 全息路口基于路口的雷达、摄像机两种感知设备，构建智能感知（见线 D）
3. 全息路口的核心是：**通过路侧边缘计算拟合多方向雷达和视频信息**，产生车牌、位置、车辆速度、行驶姿态、车辆属性、轨迹等多种基础元数据，在车路协同平台-大数据平台上，通过数据建模的方式，快速合成多种业务指标，如路口溢出、排队长度、路口停车次数、路口行驶速度、各方向过车流量、交通违法事件等，全面服务于城市交通治理全场景。

<!-- slide -->

通过路侧边缘计算拟合多方向雷达和视频信息，核心是：数据融合算法。

<!-- slide -->

- 背景介绍
- **算法价值**
- 项目说明
  - 为什么需要融合
  - 硬件准备
  - 参考标准
  - 目标期望
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求


<!-- slide -->

1. 全量刻画路口内的车路信息：

涵盖路口内的标志、标线、交通设备，并通过雷达和视频结合实时获取车辆的轨迹和车牌。

<!-- slide -->

2. 单路口以及多路口间的红绿灯自适应调节：

通过路侧单元对信号机的智慧化管理实现单路口的自适应控制和多路口的协调。

<!-- slide -->

3. 交通态势的精准化和精细化感知：

通过记录每秒车辆的位置和车牌，可以实时感知交通态势，并可通过历史记录和路网连接关系，分析车辆 OD（Origin-Destination）态势，掌握城市交通规律。

<!-- slide -->

4. 事件即时上报：

实现单车事故、多车事故、逆行、违停、实线变道、拥堵、流量突变等交通事件即时上报，同时关联到六合一路段数据。

<!-- slide -->

5. 安全隐患的精准挖掘：

通过轨迹挖掘路口冲突点、常发变道点、大车路径（计算路口安全视距）等安全隐患点，为路口秩序管理提供详实数据。

<!-- slide -->

6. 面向车联网的信息服务：

通过路侧单元可以把交通态势、事件、控制信息以及路口渠化信息和公交车、120 急救车等特种车辆进行交互，未来可以和半自动或者无人驾驶车辆通信。

<!-- slide -->

以上都需要通过精准、实时的感知做为基础支撑，而单个硬件感知数据存在局限性，需要多种不同设备同时感知，分别得出结构化数据后，通过感知的交通参与者坐标进行多维度数据的融合。

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
  - **为什么需要融合**
  - 硬件准备
  - 参考标准
  - 目标期望
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求


<!-- slide -->

| 能力纬度     | 摄像头 | 毫米波雷达 |
| ------------ | ------ | ---------- |
| 感知维度     | 2D     | 2D         |
| 可视角度     | ++     | +          |
| 检测距离     | ++     | +++        |
| 水平位置精度 | +      | -          |
| 距离精度     | -      | +          |

<!-- slide -->

| 能力纬度           | 摄像头 | 毫米波雷达 |
| ------------------ | ------ | ---------- |
| 速度精度           | -      | ++         |
| 恶劣天气工作能力   | -      | +++        |
| 夜间或强光工作能力 | -      | +++        |
| 目标分类能力       | +++    | -          |
| 微小障碍物探测能力 | ++     | -          |

> 毫米波雷达、摄像机，能力侧重不同，更精确的感知需要融合这两种设备的能力

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
  - 为什么需要融合
  - **硬件准备**
  - 参考标准
  - 目标期望
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求
 

<!-- slide -->

1. 一款智能交通摄像机，可选型号：
   - 大华
     - CP435
     - DH-CP902-RU2D
   - 华为
     - X2391-10-TL
     - M2391-TG
   - 文安
     - VT-E206-35mm
   - 海康 
    - iDS-TCE900-A 16mm（又名 iDS-2CD9396-AS） 
    - iDS-TCE900-B 16mm（又名 iDS-2CD9396-BS）

<!-- slide -->

2. 一款毫米波雷达，可选型号：
   - 华为
     - ACC7320（HTR）
     - ACC7320（CSR）
     - ACC7322
   - 木牛
     - WAYV T300
   - 其他厂家的，支持二次开发的毫米波雷达

<!-- slide -->

3. 一款工控机或 MEC，硬件要求是：

   - 4 核心 cpu
   - 8G 内存
   - 500G 硬盘
   - 至少一个 RJ45 网口

4. 可选 MEC 型号：
   - 英伟达 NVIDIA XAVIER NX(Jetson Xavier NX 模组)
   - 华为 ITS800

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
  - 为什么需要融合
  - 硬件准备
  - **参考标准**
  - 目标期望
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求
 

<!-- slide -->

1. T/ITS 0117-2020 合作式智能运输系统 RSU 与中心子系统间数据接口规范
2. T/ITS 0170-2021 智能交通 道路交通信号控制机接口技术要求
3. T/ITS 0171-2021 智能交通 道路摄像机接口技术要求
4. T/ITS 0172-2021 智能交通 毫米波雷达交通状态检测器接口技术要求
5. T/ITS 0173-2021 智能交通 路侧激光雷达接口技术要求
6. T/CSAE 53-2020 车用通信（OBU）系统应用层及应用数据交互标准（第一阶段）
7. T/CSAE 157-2020 车用通信（OBU）系统应用层及应用数据交互标准（第二阶段）

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
  - 为什么需要融合
  - 硬件准备
  - 参考标准
  - **目标期望**
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求


<!-- slide -->

1. 目标检测

检测道路上的交通参与者目标的存在，得出：

- 目标三维位置
- 目标三维尺寸
- 目标朝向
- 等

> 此功能依靠雷达完成

<!-- slide -->

2. 目标识别

通过 AI 图像分类算法，对交通参与者进行分类

- 大型机动车
- 小型机动车
- 两轮车
- 行人
- 障碍物
- 等

> 此功能依靠摄像机完成

<!-- slide -->

3. 目标跟踪

通过连续的数据帧，识别同一目标（目标跟踪算法）。

- 同样的目标，返回的结构化数据中，id 不变
- 实时计算速度
- 实时计算方向
- 实时计算加速度
- 历史轨迹

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
  - 为什么需要融合
  - 硬件准备
  - 参考标准
  - 目标期望
- **参考融合方案**
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求


<!-- slide -->


分别利用 LiDAR 及路端相机+LiDAR 传感器信息，计算 3D 目标位置、置信度等结果，在世界坐标系中将计算结果进行后融合。车路协同感知后融合整体流程如下图:

<!-- slide -->

![车路协同感知融合参考方案流程](/assets/yuanli.png)

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
  - 为什么需要融合
  - 硬件准备
  - 参考标准
  - 目标期望
- 参考融合方案
  - **问题建模**
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求
 

<!-- slide -->

1. 输入：
   - 路端数据 - 图像
   - 路端数据 - 点云
   - 以及对应的时间戳和标定文件
2. 输出：
   - 区域内的障碍物目标 3D 位置
   - 朝向
   - 等

> 具体输出数据，参见《1080标准》交通参与者感知部分

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
  - 为什么需要融合
  - 硬件准备
  - 参考标准
  - 目标期望
- 参考融合方案
  - 问题建模
  - **标定和坐标系**
  - 坐标系关系
  - 时间同步
- 答题要求


<!-- slide -->

> 融合基本原理是基于数据坐标定位的融合，则如需获得准确坐标需要对设备进行标定

![标定和坐标系](/assets/biaoding.png)

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
  - 为什么需要融合
  - 硬件准备
  - 参考标准
  - 目标期望
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - **坐标系关系**
  - 时间同步
- 答题要求
 

<!-- slide -->

#### 1. 虚拟世界坐标系  

虚拟世界坐标系是以地面某一随机位置为原点，x 轴、y 轴与地面平行，z 轴垂直于地面竖直向上，符合右手坐标系规则。

<!-- slide -->

#### 2. LiDAR 坐标系  

LiDAR 坐标系是以 LiDAR 传感器的几何中心为原点，x 轴水平向前，y 轴水平向左，z 轴竖直向上，符合右手坐标系规则。

<!-- slide -->

#### 3. 虚拟 LiDAR 坐标系  

虚拟 LiDAR 坐标系是以 LiDAR 传感器的几何中心为原点，x 轴平行地面向前，y 轴平行地面向左，z 轴垂直于地面竖直向上，符合右手坐标系规则。由于路端 LiDAR 与地面存在俯仰角，为方便研究，通过路端 LiDAR 外参矩阵，统一将路端 LiDAR 坐标系转到虚拟 LiDAR 坐标系，同时将路端点云全部转到虚拟 LiDAR 坐标系。

<!-- slide -->

#### 4. 相机坐标系  

相机坐标系是以相机光心为原点，x 轴和 y 轴与图像平面坐标系的 x 轴和 y 轴平行，z 轴与相机光轴平行向前、与图像平面垂直。通过相机到 LiDAR 的外参矩阵，可以将点从相机坐标系转到 LiDAR 坐标系。

<!-- slide -->

#### 5. 图像坐标系  

图像坐标是以相机主点（即相机光轴与图像平面的交点，一般位于图像平面中心）为原点，x 轴水平向右，y 轴水平向下的二维坐标系。相机内参可以实现从相机坐标到图像坐标的投影。

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - **时间同步**
- 答题要求
  - 开发说明
  - 评测指标
  - 提交材料
  - 开发工具及接口

<!-- slide -->

仅有位置，无法确定来自不通设备感知的数据，属于同一个目标，还需要时间相同。因道路上车辆速度较快，则需要设备具有更高的时间同步精度。
时间同步是为实现车路协同针对路端和车端传感器所做的同步操作。利用 GPS 授时以同步各传感器时间，并在采集每帧数据时得到相应的时间戳。时间戳可通过时间转换得到相应的标准时间。

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求
  - **开发说明**
  - 评测指标
  - 提交材料
  - 开发工具及接口

<!-- slide -->

依托部署在路侧的毫米波雷达和交通摄像机，开发数据融合算法。

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求
  - 开发说明
  - **评测指标**
  - 提交材料
  - 开发工具及接口

<!-- slide -->

### 1. 目标检测精度(mAP)：

针对车辆、行人等不同类别目标，计算 3D 边界框的尺寸、 位置和置信度， 基于不同的 IoU 阈值计算检测精度(Average Precision, AP) ，最终计算所有类别 AP 的平均值（mean Average Precision, mAP）；

<!-- slide -->

### 2. 数据传输消耗(Bit Number)：

以比特数(Bit)度量车路融合检测过程使用的路端传输数据量；更少的数据传输可以降低带宽消耗，减少通信时延。

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求
  - 开发说明
  - 评测指标
  - **提交材料**
  - 开发工具及接口

<!-- slide -->

1. 项目报告书、项目成果演示视频
2. 适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现系统的设计方案和使用手册
3. 摄像机测试数据和毫米波雷达测试数据
4. 数据融合测试报告

<!-- slide -->

- 背景介绍
- 算法价值
- 项目说明
- 参考融合方案
  - 问题建模
  - 标定和坐标系
  - 坐标系关系
  - 时间同步
- 答题要求
  - 开发说明
  - 评测指标
  - 提交材料
  - **开发工具及接口**

<!-- slide -->

1. 文档材料：描述工具不限，描述方式优选 MarkDown 方式。
2. 开发材料：开发工具不限，编程语言不限，优选 C++、Rust

<!-- slide -->

## 文档下载

Word 版下载：[适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现.docx](http://doc.hiacent.info/mec0/适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现.docx)

PDF 版下载：[适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现.pdf](http://doc.hiacent.info/mec0/适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现.pdf)

MD 源码下载：[适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现.md](http://doc.hiacent.info/mec0/适用于车路协同的基于毫米波雷达和智能摄像机的数据融合算法实现.md)

<!-- slide -->

参考资料

<!-- slide -->

1. [OpenV2X开源社区](https://www.shanghaiopen.org.cn/blog/3/openv2x-5g-rsoi-5gopenv2x-81)
2. [汽车学堂](https://www.auto-mooc.com)
3. [3D视觉工坊](https://space.bilibili.com/483478083)
4. [基于图像与雷达的数据融合算法](https://www.bilibili.com/video/BV1d44y1P7Pk?spm_id_from=333.337.search-card.all.click)
5. [国内首个面向自动驾驶领域的多传感器数据标定融合教程](https://mp.weixin.qq.com/s/fVWHyAwcfDGRRdaRpFOg4Q)

<!-- slide -->

6. [开源：一个基于迭代误差状态卡尔曼滤波(IESKF)的Livox-IMU车载SLAM系统实现](https://github.com/GDUT-Kyle/LINS-LIVOX)
7. [上条，对应视频](https://www.bilibili.com/video/BV1ka41127bV?spm_id_from=333.337.search-card.all.click)
8. [最新开源！用于自动驾驶汽车的激光雷达全局定位算法！](https://www.bilibili.com/video/BV1SB4y1T7nT/?spm_id_from=333.788.recommend_more_video.5)
9. [[开源] 用于多个Livox激光雷达的外参自动标定系统](https://www.bilibili.com/video/BV1oR4y1c7h5/?spm_id_from=333.788.recommend_more_video.2)

<!-- slide -->

# THE END

### Tanks
